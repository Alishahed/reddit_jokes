{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **A model for classifying jokes to adult and clean**\n",
    "In this notebook explore training a model to classify jokes to adult and clean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37215 entries, 0 to 37214\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   index                37215 non-null  int64  \n",
      " 1   thread_id            37215 non-null  object \n",
      " 2   thread_title         37215 non-null  object \n",
      " 3   thread_selftext      37215 non-null  object \n",
      " 4   thread_score         37215 non-null  float64\n",
      " 5   thread_num_comments  37215 non-null  float64\n",
      " 6   thread_created_utc   37215 non-null  object \n",
      " 7   thread_upvote_ratio  37215 non-null  float64\n",
      " 8   thread_over_18       37215 non-null  bool   \n",
      " 9   thread_created_pst   37215 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(1), object(5)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import scipy.sparse\n",
    "from scipy.special import expit as sigmoid  # Import the sigmoid function\n",
    "import joblib\n",
    "\n",
    "\n",
    "# pd cosmetics\n",
    "pd.set_option('display.max_colwidth', 3000)\n",
    "pd.set_option('display.max_rows', 3000)\n",
    "pd.set_option('display.max_columns', 3000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_jokes_slim = pd.read_csv('./data/reddit_jokes_slim_processed.csv')\n",
    "df_jokes_slim.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clean jokes in dataset = 31576\n",
      "number of adult jokes in dataset = 5639\n"
     ]
    }
   ],
   "source": [
    "adult_jokes = df_jokes_slim[df_jokes_slim.thread_over_18 == True]\n",
    "clean_jokes  = df_jokes_slim[df_jokes_slim.thread_over_18 == False]\n",
    "\n",
    "print (f'number of clean jokes in dataset = {len(clean_jokes)}')\n",
    "print (f'number of adult jokes in dataset = {len(adult_jokes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loggistic regression\n",
    "We are dealing with imbalance data set as the number of clean jokes is much higher than the number of adult jokes. We use Synthatic Minority Over-sampling Technique  (SMOTE) to balance two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        39362     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.50185D+04    |proj g|=  3.04690D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.99301D+04    |proj g|=  4.96962D+01\n",
      "\n",
      "At iterate  100    f=  1.98036D+04    |proj g|=  9.46964D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "39362    143    170      1     0     0   5.396D-02   1.980D+04\n",
      "  F =   19802.654313255058     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.87      0.87      6250\n",
      "        True       0.88      0.88      0.88      6381\n",
      "\n",
      "    accuracy                           0.88     12631\n",
      "   macro avg       0.88      0.88      0.88     12631\n",
      "weighted avg       0.88      0.88      0.88     12631\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/jokes_adult_clean_classifier_logreg.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "jokes_df = pd.read_csv('./data/reddit_jokes_slim_processed.csv')\n",
    "\n",
    "# Combine the title and selftext into one column\n",
    "jokes_df['combined_text'] = jokes_df['thread_title'] + ' ' + jokes_df['thread_selftext']\n",
    "\n",
    "# Text Encoding with TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(jokes_df['combined_text'])\n",
    "joblib.dump(tfidf, 'models/tfidf_vectorizer.pkl')  # Save the fitted vectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Combine the matrices\n",
    "#X = scipy.sparse.hstack([tfidf_matrix_title, tfidf_matrix_text])\n",
    "\n",
    "# Target variable\n",
    "y = jokes_df['thread_over_18']\n",
    "\n",
    "# Handling Class Imbalance with SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "#scaler = StandardScaler(with_mean=False)\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# Model Building\n",
    "model = LogisticRegression(max_iter= 2000,verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "joblib.dump(model, 'models/jokes_adult_clean_classifier_logreg.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke: Why don't scientists trust atoms? Because they make up everything!\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: What do you call a fake noodle? An impasta!\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: How do you organize a space party? You planet!\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: What's an astronaut's favorite part of the computer? The space bar.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: Why did the bicycle fall over? It was two-tired.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: What do you call cheese that isn't yours? Nacho cheese.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: Why couldn't the bicycle stand up by itself? It was two-tired.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: How does a penguin build its house? Igloos it together.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: Why don’t skeletons fight each other? They don’t have the guts.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: What did the grape do when he got stepped on? He let out a little wine.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: I told my wife she should embrace her mistakes. She gave me a hug.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: Why don't some couples go to the gym? Because some relationships don't work out!\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: I'm reading a book on the history of glue. Can't put it down.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: I told my suitcases there will be no vacation this year. Now I'm dealing with emotional baggage.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: It's inappropriate to make a 'dad joke' if you're not a dad. It's a faux pa.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: I used to play piano by ear, but now I use my hands.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: The rotation of earth really makes my day.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: I have a joke about time travel, but you didn't like it.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: Parallel lines have so much in common. It’s a shame they’ll never meet.\n",
      "Classified as: Clean\n",
      "\n",
      "Joke: My wife told me to take the spider out instead of killing it. We went and had some drinks. Cool guy, wants to be a web developer.\n",
      "Classified as: Clean\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "#tfidf_vectorizer = tfidf\n",
    "\n",
    "# Example jokes\n",
    "jokes = [\n",
    "    \"Why don't scientists trust atoms? Because they make up everything!\",\n",
    "\"What do you call a fake noodle? An impasta!\",\n",
    "\"How do you organize a space party? You planet!\",\n",
    "\"What's an astronaut's favorite part of the computer? The space bar.\",\n",
    "\"Why did the bicycle fall over? It was two-tired.\",\n",
    "\"What do you call cheese that isn't yours? Nacho cheese.\",\n",
    "\"Why couldn't the bicycle stand up by itself? It was two-tired.\",\n",
    "\"How does a penguin build its house? Igloos it together.\",\n",
    "\"Why don’t skeletons fight each other? They don’t have the guts.\",\n",
    "\"What did the grape do when he got stepped on? He let out a little wine.\",\n",
    "\"I told my wife she should embrace her mistakes. She gave me a hug.\",\n",
    "\"Why don't some couples go to the gym? Because some relationships don't work out!\",\n",
    "\"I'm reading a book on the history of glue. Can't put it down.\",\n",
    "\"I told my suitcases there will be no vacation this year. Now I'm dealing with emotional baggage.\",\n",
    "\"It's inappropriate to make a 'dad joke' if you're not a dad. It's a faux pa.\",\n",
    "\"I used to play piano by ear, but now I use my hands.\",\n",
    "\"What did the toaster say to the slice of bread? 'I want you inside me.'\",\n",
    "\"'Give it to me! Give it to me!' she yelled. 'I'm so wet, give it to me now!' She could scream all she wanted, but I was keeping the umbrella.\",\n",
    "\"Parallel lines have so much in common. It’s a shame they’ll never meet.\",\n",
    "\"My wife told me to take the spider out instead of killing it. We went and had some drinks. Cool guy, wants to be a web developer.\"\n",
    "]\n",
    "\n",
    "# Preprocessing function (customize this according to how your data was preprocessed)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'\\d+', '', text)  # Removing numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Removing extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Removing punctuation\n",
    "    return text\n",
    "\n",
    "# Preprocess jokes\n",
    "processed_jokes = [preprocess_text(joke) for joke in jokes]\n",
    "\n",
    "# Vectorize jokes\n",
    "tfidf_vectorizer = joblib.load('models/tfidf_vectorizer.pkl')\n",
    "jokes_vectorized = tfidf_vectorizer.transform(processed_jokes)\n",
    "\n",
    "model = joblib.load('models/jokes_adult_clean_classifier_logreg.pkl')\n",
    "# Prediction\n",
    "predictions = model.predict(jokes_vectorized)\n",
    "\n",
    "# Output results\n",
    "for joke, pred in zip(jokes, predictions):\n",
    "    print(f\"Joke: {joke}\\nClassified as: {'Adult' if pred else 'Clean'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_ve_39_DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
